{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce8129a-d71c-4a3c-acbd-a5822178a94b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Langchain Agent with MCP Tools (비동기 버전)\n",
    "\n",
    "이 노트북은 **Langchain**과 **Databricks**를 활용하여 MCP(Model Context Protocol) 기반 Tool-calling Agent를 구현하는 예제입니다.\n",
    "\n",
    "## 왜 비동기(Async) 버전인가?\n",
    "\n",
    "> ⚠️ **중요**: Langchain의 MCP Tool은 **비동기(Async) 방식만 지원**합니다. 따라서 MCP 서버와 연동하는 Agent를 구현할 때는 비동기 패턴을 사용해야 합니다. 이 노트북은 비동기 Agent 구현의 표준 예제입니다.\n",
    "\n",
    "## 이 노트북에서 다루는 내용\n",
    "\n",
    "- Langchain + Databricks MCP Client를 활용한 Agent 구현\n",
    "- MLflow의 `ResponsesAgent`를 사용한 래퍼 클래스 작성\n",
    "- Agent 출력 테스트 및 스트리밍 처리\n",
    "- Mosaic AI Agent Evaluation을 통한 평가\n",
    "- Unity Catalog에 모델 등록 및 배포\n",
    "\n",
    "## 실행 환경\n",
    "\n",
    "- Databricks Serverless 또는 DBR 17 이상 클러스터\n",
    "- Unity Catalog 활성화 필수\n",
    "\n",
    "## 사전 요구사항\n",
    "\n",
    "- 이 노트북의 모든 `TODO` 항목을 확인하고 수정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fa5e662-e6e3-443b-9da9-2d7a6b824a9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq backoff databricks-langchain uv databricks-agents mlflow-skinny[databricks]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad62dac7-b239-4c0a-8614-1de9e420eee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent 코드 정의\n",
    "\n",
    "아래에서 Agent 코드를 단일 셀에 정의합니다. `%%writefile` 매직 명령어를 사용하여 로컬 Python 파일로 저장하면, 이후 MLflow 로깅 및 배포 시 활용할 수 있습니다.\n",
    "\n",
    "### 주요 구성 요소\n",
    "- **ChatDatabricks**: Databricks Foundation Model API 연동\n",
    "- **DatabricksMCPServer**: MCP 서버 연결 설정\n",
    "- **create_agent**: Langchain Agent 생성\n",
    "\n",
    "Agent에 추가할 수 있는 도구 예제는 [공식 문서](https://docs.databricks.com/generative-ai/agent-framework/agent-tool.html)를 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ca0ae6-8707-4a35-926f-d9c64fee7f20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile mcp_langchain_agent.py\n",
    "import asyncio\n",
    "from typing import Optional\n",
    "from functools import lru_cache\n",
    "\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import (\n",
    "    DatabricksMCPServer,\n",
    "    DatabricksMultiServerMCPClient,\n",
    ")\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"당신은 MCP(Model Context Protocol) 도구를 활용하는 AI 어시스턴트입니다.\n",
    "\n",
    "## MCP Tool 사용 기준\n",
    "- API 관련정보를 알고 싶으면 search 툴을 사용하세요.\n",
    "  ex) \"API 인증 방법을 알려주세요\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_mcp_agent(\n",
    "    model_name: str = \"databricks-gpt-5-2\",\n",
    "    connection_name: str = \"my-mcp-server\",\n",
    "    system_prompt: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"MCP 기반 Langchain Agent 생성 팩토리 함수\n",
    "    \n",
    "    Args:\n",
    "        model_name: Databricks Foundation Model 엔드포인트 이름\n",
    "        connection_name: Unity Catalog에 등록된 MCP 서버 연결 이름\n",
    "        system_prompt: 커스텀 시스템 프롬프트 (선택사항)\n",
    "    \n",
    "    Returns:\n",
    "        Langchain Agent 인스턴스\n",
    "    \"\"\"\n",
    "    \n",
    "    # 모델 설정\n",
    "    model = ChatDatabricks(endpoint=model_name)\n",
    "    \n",
    "    # MCP 클라이언트 설정\n",
    "    ws = WorkspaceClient()\n",
    "    host = ws.config.host\n",
    "    mcp_server_url = f\"{host}/api/2.0/mcp/external/{connection_name}\"\n",
    "    \n",
    "    mcp_server = DatabricksMCPServer(\n",
    "        name=\"mcp_server\",\n",
    "        url=mcp_server_url,\n",
    "        workspace_client=ws,\n",
    "    )\n",
    "    client = DatabricksMultiServerMCPClient(servers=[mcp_server])\n",
    "    \n",
    "    # Tools 로드 (비동기 - Langchain MCP Tool은 비동기만 지원)\n",
    "    tools = asyncio.run(client.get_tools())\n",
    "\n",
    "    for tool in tools:\n",
    "        tool.handle_tool_error = lambda e: f\"Tool error: {e}. 다른 방법을 시도해 주세요.\"\n",
    "    \n",
    "    # Agent 생성\n",
    "    return create_agent(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        system_prompt=system_prompt or DEFAULT_SYSTEM_PROMPT\n",
    "    )\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_default_agent():\n",
    "    \"\"\"기본 Agent 캐싱 (싱글톤)\"\"\"\n",
    "    return create_mcp_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d941654c-196d-4acc-9e78-ec8b39719ac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile mcp_langchain_wrapper_agent.py\n",
    "\"\"\"\n",
    "MCP Langchain Agent Wrapper\n",
    "\n",
    "MLflow ResponsesAgent를 래핑하여 Langchain의 비동기 Agent를 \n",
    "동기 인터페이스로 변환합니다.\n",
    "\n",
    "Langchain의 MCP Tool은 비동기만 지원하므로, 이 래퍼 클래스를 통해\n",
    "MLflow의 predict/predict_stream 인터페이스와 호환되도록 합니다.\n",
    "\"\"\"\n",
    "from typing import Any, Generator, AsyncGenerator\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    "    to_chat_completions_input,\n",
    "    create_text_output_item,\n",
    "    output_to_responses_items_stream,\n",
    ")\n",
    "\n",
    "from mcp_langchain_agent import get_default_agent, create_mcp_agent\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.messages.ai import AIMessageChunk\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "\n",
    "class MCPWrappedResponsesAgent(ResponsesAgent):\n",
    "    \"\"\"비동기 Langchain Agent를 MLflow ResponsesAgent로 래핑하는 클래스\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.agent = get_default_agent()\n",
    "\n",
    "    # Make a prediction (single-step) for the agent\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\" or event.type == \"error\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(output=outputs, custom_outputs=request.custom_inputs)\n",
    "\n",
    "    async def _predict_stream_async(\n",
    "        self,\n",
    "        request: ResponsesAgentRequest,\n",
    "    ) -> AsyncGenerator[ResponsesAgentStreamEvent, None]:\n",
    "        cc_msgs = to_chat_completions_input([i.model_dump() for i in request.input])\n",
    "        # Stream events from the agent graph\n",
    "        async for event in self.agent.astream(\n",
    "            {\"messages\": cc_msgs}, stream_mode=[\"updates\", \"messages\"]\n",
    "        ):\n",
    "            print(f\"\\n{event=}\\n\")\n",
    "            if event[0] == \"updates\":\n",
    "                # Stream updated messages from the workflow nodes\n",
    "                for node_data in event[1].values():\n",
    "                    if len(node_data.get(\"messages\", [])) > 0:\n",
    "                        all_messages = []\n",
    "                        for msg in node_data[\"messages\"]:\n",
    "                            if isinstance(msg, ToolMessage) and not isinstance(msg.content, str):\n",
    "                                msg.content = json.dumps(msg.content)\n",
    "                            all_messages.append(msg)\n",
    "                        for item in output_to_responses_items_stream(all_messages):\n",
    "                            yield item\n",
    "            elif event[0] == \"messages\":\n",
    "                # Stream generated text message chunks\n",
    "                try:\n",
    "                    chunk = event[1][0]\n",
    "                    if isinstance(chunk, AIMessageChunk) and (content := chunk.content):\n",
    "                        print(f\"\\n{content=}\\n\")\n",
    "                        yield ResponsesAgentStreamEvent(\n",
    "                            **self.create_text_delta(delta=content, item_id=chunk.id),\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    print(f\"DEBUG: Error in messages handling: {e}\")\n",
    "\n",
    "    # Stream predictions for the agent, yielding output as it's generated\n",
    "    def predict_stream(\n",
    "        self, request: ResponsesAgentRequest\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        agen = self._predict_stream_async(request)\n",
    "\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "        except RuntimeError:\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "\n",
    "        ait = agen.__aiter__()\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                item = loop.run_until_complete(ait.__anext__())\n",
    "            except StopAsyncIteration:\n",
    "                break\n",
    "            else:\n",
    "                yield item\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# MLflow model registration\n",
    "# ------------------------------------------------------------------------------\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = MCPWrappedResponsesAgent()\n",
    "mlflow.models.set_model(AGENT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b99e9e1c-186b-46dd-b8b4-c25d09138f57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent 테스트\n",
    "\n",
    "Agent와 상호작용하여 출력을 테스트합니다. `ResponsesAgent` 내에서 메서드를 수동으로 추적했기 때문에, Agent가 수행하는 각 단계의 트레이스를 확인할 수 있습니다. Langchain을 통한 LLM 호출은 autologging에 의해 자동으로 추적됩니다.\n",
    "\n",
    "아래의 예시 입력을 실제 도메인에 맞는 예시로 변경하여 테스트하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4db424d-892b-4259-8baf-891d49d9cd93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26acf5a7-be8d-4f05-a928-dff5456c1b52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6555e707-d303-4f36-b284-83de80beb367",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mcp_langchain_wrapper_agent import AGENT\n",
    "\n",
    "# 단일 응답 테스트 (비스트리밍)\n",
    "AGENT.predict(\n",
    "    {\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"사용 가능한 API 목록을 알려주세요.\"}], \n",
    "        \"custom_inputs\": {\"session_id\": \"test-session-123\"}\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e282ce4e-b1cf-40fc-aac1-de45812d3f8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mcp_langchain_wrapper_agent import AGENT\n",
    "\n",
    "# 스트리밍 응답 테스트\n",
    "for chunk in AGENT.predict_stream(\n",
    "    {\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"사용 가능한 API 목록을 알려주세요. 상세 정보와 예제 코드도 포함해주세요.\"}], \n",
    "        \"custom_inputs\": {\"session_id\": \"test-session-123\"}\n",
    "    },\n",
    "):\n",
    "    print(\"=\"*60)\n",
    "    print(chunk.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7e0ed52-347d-42ab-ac51-6cd8a6623a73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Agent를 MLflow 모델로 로깅\n",
    "\n",
    "배포 시 자동 인증 패스스루를 위해 Databricks 리소스를 지정합니다.\n",
    "\n",
    "- **TODO**: Unity Catalog 함수가 [Vector Search 인덱스](https://docs.databricks.com/generative-ai/agent-framework/unstructured-retrieval-tools.html)를 쿼리하거나 [외부 함수](https://docs.databricks.com/generative-ai/agent-framework/external-connection-tools.html)를 활용하는 경우, 해당 Vector Search 인덱스와 UC 연결 객체를 리소스로 포함해야 합니다. 자세한 내용은 [공식 문서](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough)를 참고하세요.\n",
    "\n",
    "Agent 코드를 Python 파일에서 로깅합니다. [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code) 참고."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16716a86-a458-4485-9089-1849b4a8f286",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 12"
    }
   },
   "outputs": [],
   "source": [
    "# 배포 시 자동 인증 패스스루를 위한 Databricks 리소스 설정\n",
    "import mlflow\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint, DatabricksUCConnection\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "# TODO: 환경에 맞게 아래 설정값을 수정하세요\n",
    "LLM_ENDPOINT_NAME = \"databricks-gpt-5-2\"  # 사용할 LLM 엔드포인트\n",
    "MCP_SERVER_CONNECTION_NAME = \"my-mcp-server\"  # Unity Catalog에 등록된 MCP 서버 연결 이름\n",
    "\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "    DatabricksUCConnection(connection_name=MCP_SERVER_CONNECTION_NAME)\n",
    "]\n",
    "\n",
    "# 입력 예시 (모델 시그니처 추론용)\n",
    "input_example = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"사용 가능한 API 목록을 알려주세요.\"\n",
    "        }\n",
    "    ],\n",
    "    \"custom_inputs\": {\n",
    "        \"session_id\": \"test-session-123\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# MLflow에 Agent 로깅\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"mcp_langchain_agent\",\n",
    "        python_model=\"mcp_langchain_wrapper_agent.py\",\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            \"databricks-langchain\",\n",
    "            \"backoff\",\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "        ],\n",
    "        code_paths=[\n",
    "            \"mcp_langchain_agent.py\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d006dd14-e9cc-4e68-aa46-69393e7af04c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## [Agent Evaluation](https://docs.databricks.com/mlflow3/genai/eval-monitor)으로 Agent 평가\n",
    "\n",
    "평가 데이터셋의 요청이나 예상 응답을 수정하고, Agent를 반복 개선하면서 평가를 실행할 수 있습니다. MLflow를 활용하여 계산된 품질 메트릭을 추적합니다.\n",
    "\n",
    "[사전 정의된 LLM 스코어러](https://docs.databricks.com/mlflow3/genai/eval-monitor/predefined-judge-scorers)를 사용하거나, [커스텀 메트릭](https://docs.databricks.com/mlflow3/genai/eval-monitor/custom-scorers)을 추가하여 Agent를 평가하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08ff3f52-99c1-49cc-9e47-dfb4707701cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 14"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Safety, RetrievalRelevance, RetrievalGroundedness\n",
    "\n",
    "# 평가 데이터셋 정의\n",
    "# TODO: 실제 사용 사례에 맞게 질문과 예상 응답을 수정하세요\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"사용 가능한 API 목록을 알려주세요.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"인증 방법을 알려주세요.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "# Agent 평가 실행\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda input: AGENT.predict({\"input\": input, \"custom_inputs\": {\"session_id\": \"evaluation-session\"}}),\n",
    "    scorers=[RelevanceToQuery(), Safety()],  # 필요에 따라 스코어러 추가\n",
    ")\n",
    "\n",
    "# MLflow UI에서 평가 결과 확인 (콘솔 출력 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab5fabfc-a657-4006-8330-134b13d9e36a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 배포 전 Agent 검증\n",
    "\n",
    "Agent를 등록하고 배포하기 전에 [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) API를 통해 사전 배포 검증을 수행합니다. 자세한 내용은 [공식 문서](https://docs.databricks.com/machine-learning/model-serving/model-serving-debug.html#validate-inputs)를 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3acdcf0-461e-4071-bd9f-ffdf77deacac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 배포 전 검증 - 로깅된 모델이 정상적으로 예측을 수행하는지 확인\n",
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/mcp_langchain_agent\",\n",
    "    input_data={\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"사용 가능한 API 목록을 알려주세요.\"}], \n",
    "        \"custom_inputs\": {\"session_id\": \"validation-session\"}\n",
    "    },\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e15b7c0-2e96-4efe-841f-1f0d4210db06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Unity Catalog에 모델 등록\n",
    "\n",
    "아래의 `catalog`, `schema`, `model_name`을 업데이트하여 MLflow 모델을 Unity Catalog에 등록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4b97dfc-4218-4341-9db2-594de88caac9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: Unity Catalog 모델의 catalog, schema, model_name을 환경에 맞게 수정하세요\n",
    "catalog = \"ml\"\n",
    "schema = \"default\"\n",
    "model_name = \"mcp-langchain-agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# Unity Catalog에 모델 등록\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94c921e6-2f62-4add-8254-d703c5325749",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent 배포\n",
    "\n",
    "Agent를 Databricks Model Serving 엔드포인트로 배포합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac63b207-a575-43c1-b73f-a9e0856a5597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# 참고: scale_to_zero=True를 전달하면 비용 절감을 위한 스케일 투 제로가 활성화됩니다.\n",
    "# 프로덕션 워크로드에는 권장되지 않습니다 (스케일 제로 상태에서는 용량이 보장되지 않음).\n",
    "# 스케일 제로 상태의 엔드포인트는 다시 스케일업하는 동안 응답 시간이 길어질 수 있습니다.\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME, \n",
    "    uc_registered_model_info.version, \n",
    "    tags={\"endpointSource\": \"local_development\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1171890-c406-4b52-9253-e19f7357cab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 다음 단계\n",
    "\n",
    "Agent가 배포되면 다음 작업을 수행할 수 있습니다:\n",
    "\n",
    "- **AI Playground에서 테스트**: 추가 검증을 위해 대화형으로 Agent 테스트\n",
    "- **피드백 수집**: 조직 내 전문가(SME)와 Agent 공유하여 피드백 수집\n",
    "- **프로덕션 애플리케이션에 통합**: 실제 서비스에 Agent 임베딩\n",
    "\n",
    "자세한 내용은 [공식 문서](https://docs.databricks.com/generative-ai/deploy-agent.html)를 참고하세요."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "driver_async",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
