{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce8129a-d71c-4a3c-acbd-a5822178a94b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Langchain Agent with llms.txt (ë™ê¸° ë²„ì „)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **Langchain**ê³¼ **Databricks**ë¥¼ í™œìš©í•˜ì—¬ llms.txt ê¸°ë°˜ Tool-calling Agentë¥¼ êµ¬í˜„í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.\n",
    "\n",
    "## ë™ê¸°(Sync) ë²„ì „ì´ë€?\n",
    "\n",
    "> âœ… **Langchain ë™ê¸° ë°©ì‹ì˜ í‘œì¤€ ì˜ˆì œì…ë‹ˆë‹¤.** Langchainì˜ `stream_mode=\"messages\"`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ê¸° ë°©ì‹ìœ¼ë¡œ í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ë¹„ë™ê¸° ì²˜ë¦¬ê°€ í•„ìš” ì—†ëŠ” í™˜ê²½ì—ì„œ ë” ê°„ë‹¨í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## llms.txt ì ‘ê·¼ ë°©ì‹\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ MCP ëŒ€ì‹  **llms.txt** íŒŒì¼ì„ í™œìš©í•˜ëŠ” ê²½ëŸ‰ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
    "- MCPë³´ë‹¤ ê°€ë³ê³  ì„¤ì •ì´ ê°„ë‹¨\n",
    "- RAGë³´ë‹¤ ì •í™•í•œ ë¬¸ì„œ ì°¸ì¡°\n",
    "- llms.txtë¥¼ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ ë¬¸ì„œë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜´\n",
    "\n",
    "## ì´ ë…¸íŠ¸ë¶ì—ì„œ ë‹¤ë£¨ëŠ” ë‚´ìš©\n",
    "\n",
    "- Langchain + Databricks Foundation Model APIë¥¼ í™œìš©í•œ Agent êµ¬í˜„\n",
    "- llms.txt ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ë° í˜ì¹­ ë„êµ¬ êµ¬í˜„\n",
    "- MLflowì˜ `ResponsesAgent`ë¥¼ ì‚¬ìš©í•œ ë˜í¼ í´ë˜ìŠ¤ ì‘ì„±\n",
    "- Agent ì¶œë ¥ í…ŒìŠ¤íŠ¸ ë° ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬\n",
    "- Mosaic AI Agent Evaluationì„ í†µí•œ í‰ê°€\n",
    "- Unity Catalogì— ëª¨ë¸ ë“±ë¡ ë° ë°°í¬\n",
    "\n",
    "## ì‹¤í–‰ í™˜ê²½\n",
    "\n",
    "- Databricks Serverless ë˜ëŠ” DBR 17 ì´ìƒ í´ëŸ¬ìŠ¤í„°\n",
    "- Unity Catalog í™œì„±í™” í•„ìˆ˜\n",
    "\n",
    "## ì‚¬ì „ ìš”êµ¬ì‚¬í•­\n",
    "\n",
    "- ì´ ë…¸íŠ¸ë¶ì˜ ëª¨ë“  `TODO` í•­ëª©ì„ í™•ì¸í•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fa5e662-e6e3-443b-9da9-2d7a6b824a9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq backoff databricks-langchain uv databricks-agents mlflow-skinny[databricks]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad62dac7-b239-4c0a-8614-1de9e420eee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent ì½”ë“œ ì •ì˜\n",
    "\n",
    "ì•„ë˜ì—ì„œ Agent ì½”ë“œë¥¼ ë‹¨ì¼ ì…€ì— ì •ì˜í•©ë‹ˆë‹¤. `%%writefile` ë§¤ì§ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ Python íŒŒì¼ë¡œ ì €ì¥í•˜ë©´, ì´í›„ MLflow ë¡œê¹… ë° ë°°í¬ ì‹œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
    "- **LLMSTxtLoader**: llms.txt íŒŒì¼ ë¡œë“œ ë° ì¸ë±ìŠ¤ íŒŒì‹±\n",
    "- **DocumentFetcher**: URLì—ì„œ ë¬¸ì„œ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ìœ í‹¸ë¦¬í‹°\n",
    "- **Tool ì •ì˜**: search_docs, fetch_document, get_doc_index\n",
    "- **ChatDatabricks**: Databricks Foundation Model API ì—°ë™\n",
    "\n",
    "Agentì— ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ë„êµ¬ ì˜ˆì œëŠ” [ê³µì‹ ë¬¸ì„œ](https://docs.databricks.com/generative-ai/agent-framework/agent-tool.html)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ca0ae6-8707-4a35-926f-d9c64fee7f20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile langchain_sync_agent.py\n",
    "\"\"\"\n",
    "llms.txt ê¸°ë°˜ Langchain Agent (ë™ê¸° ë²„ì „)\n",
    "\n",
    "MCPë³´ë‹¤ ê°€ë³ê³  RAGë³´ë‹¤ ì •í™•í•œ ì ‘ê·¼ë²•:\n",
    "1. llms.txtë¥¼ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš© (ì‹œì‘ ì‹œ ìë™ ë¡œë“œ)\n",
    "2. fetch_document toolë¡œ í•„ìš”í•œ ìƒì„¸ ë¬¸ì„œë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜´\n",
    "3. ë§í¬ ì•ˆì˜ ë§í¬ë„ ì¶”ì  ê°€ëŠ¥\n",
    "\n",
    "ì´ ëª¨ë“ˆì€ Langchainì˜ ë™ê¸° ë°©ì‹ í‘œì¤€ ì˜ˆì œì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import httpx\n",
    "from typing import Optional, Any\n",
    "from functools import lru_cache\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# llms.txt ë¡œë” ë° íŒŒì„œ\n",
    "# ==============================================================================\n",
    "\n",
    "class LLMSTxtLoader:\n",
    "    \"\"\"llms.txt íŒŒì¼ì„ ë¡œë“œí•˜ê³  íŒŒì‹±í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, llms_txt_url: str):\n",
    "        self.llms_txt_url = llms_txt_url\n",
    "        self._content: Optional[str] = None\n",
    "        self._index: dict[str, list[dict[str, str]]] = {}\n",
    "    \n",
    "    def load(self) -> str:\n",
    "        \"\"\"llms.txt íŒŒì¼ì„ ë™ê¸°ì ìœ¼ë¡œ ë¡œë“œ\"\"\"\n",
    "        with httpx.Client(timeout=30.0) as client:\n",
    "            response = client.get(self.llms_txt_url)\n",
    "            response.raise_for_status()\n",
    "            self._content = response.text\n",
    "            self._parse_index()\n",
    "            return self._content\n",
    "    \n",
    "    async def aload(self) -> str:\n",
    "        \"\"\"llms.txt íŒŒì¼ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ë¡œë“œ\"\"\"\n",
    "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
    "            response = await client.get(self.llms_txt_url)\n",
    "            response.raise_for_status()\n",
    "            self._content = response.text\n",
    "            self._parse_index()\n",
    "            return self._content\n",
    "    \n",
    "    def _parse_index(self) -> None:\n",
    "        \"\"\"llms.txt ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ ì¸ë±ìŠ¤ ìƒì„±\"\"\"\n",
    "        if not self._content:\n",
    "            return\n",
    "        \n",
    "        current_section = \"general\"\n",
    "        self._index = {}\n",
    "        \n",
    "        for line in self._content.split('\\n'):\n",
    "            line = line.strip()\n",
    "            \n",
    "            # ì„¹ì…˜ í—¤ë” ê°ì§€\n",
    "            if line.startswith('## '):\n",
    "                current_section = line[3:].strip()\n",
    "                if current_section not in self._index:\n",
    "                    self._index[current_section] = []\n",
    "            elif line.startswith('# '):\n",
    "                current_section = line[2:].strip()\n",
    "                if current_section not in self._index:\n",
    "                    self._index[current_section] = []\n",
    "            \n",
    "            # ë§í¬ ì¶”ì¶œ: - [title](url) ë˜ëŠ” - [title](url): description\n",
    "            link_match = re.match(r'-\\s*\\[([^\\]]+)\\]\\(([^)]+)\\)(?::\\s*(.*))?', line)\n",
    "            if link_match:\n",
    "                title, url, description = link_match.groups()\n",
    "                if current_section not in self._index:\n",
    "                    self._index[current_section] = []\n",
    "                self._index[current_section].append({\n",
    "                    'title': title,\n",
    "                    'url': url,\n",
    "                    'description': description or ''\n",
    "                })\n",
    "    \n",
    "    @property\n",
    "    def content(self) -> str:\n",
    "        \"\"\"ë¡œë“œëœ llms.txt ì›ë³¸ ë‚´ìš©\"\"\"\n",
    "        if self._content is None:\n",
    "            self.load()\n",
    "        return self._content\n",
    "    \n",
    "    @property\n",
    "    def index(self) -> dict[str, list[dict[str, str]]]:\n",
    "        \"\"\"íŒŒì‹±ëœ ì¸ë±ìŠ¤ (ì„¹ì…˜ë³„ ë§í¬ ëª©ë¡)\"\"\"\n",
    "        if not self._index and self._content is None:\n",
    "            self.load()\n",
    "        return self._index\n",
    "    \n",
    "    def get_summary(self) -> str:\n",
    "        \"\"\"ì¸ë±ìŠ¤ ìš”ì•½ ë°˜í™˜ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ìš©)\"\"\"\n",
    "        if not self._index and self._content is None:\n",
    "            self.load()\n",
    "        \n",
    "        lines = [\"# API ë¬¸ì„œ ì¸ë±ìŠ¤\\n\"]\n",
    "        for section, items in self._index.items():\n",
    "            lines.append(f\"\\n## {section}\")\n",
    "            for item in items:\n",
    "                desc = f\" - {item['description']}\" if item['description'] else \"\"\n",
    "                lines.append(f\"- {item['title']}{desc}\")\n",
    "        \n",
    "        return '\\n'.join(lines)\n",
    "    \n",
    "    def search(self, keyword: str) -> list[dict[str, str]]:\n",
    "        \"\"\"í‚¤ì›Œë“œë¡œ ì¸ë±ìŠ¤ ê²€ìƒ‰\"\"\"\n",
    "        if not self._index and self._content is None:\n",
    "            self.load()\n",
    "        \n",
    "        results = []\n",
    "        keyword_lower = keyword.lower()\n",
    "        \n",
    "        for section, items in self._index.items():\n",
    "            for item in items:\n",
    "                if (keyword_lower in item['title'].lower() or \n",
    "                    keyword_lower in item['description'].lower() or\n",
    "                    keyword_lower in section.lower()):\n",
    "                    results.append({\n",
    "                        'section': section,\n",
    "                        **item\n",
    "                    })\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ë¬¸ì„œ fetcher\n",
    "# ==============================================================================\n",
    "\n",
    "class DocumentFetcher:\n",
    "    \"\"\"URLì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str = \"\"):\n",
    "        self.base_url = base_url\n",
    "        self._cache: dict[str, str] = {}\n",
    "    \n",
    "    def fetch(self, url: str) -> str:\n",
    "        \"\"\"URLì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°ì ìœ¼ë¡œ ê°€ì ¸ì˜´\"\"\"\n",
    "        # ìƒëŒ€ URL ì²˜ë¦¬\n",
    "        if not url.startswith('http'):\n",
    "            url = urljoin(self.base_url, url)\n",
    "        \n",
    "        # ìºì‹œ í™•ì¸\n",
    "        if url in self._cache:\n",
    "            return self._cache[url]\n",
    "        \n",
    "        with httpx.Client(timeout=30.0, follow_redirects=True) as client:\n",
    "            response = client.get(url)\n",
    "            response.raise_for_status()\n",
    "            content = response.text\n",
    "            self._cache[url] = content\n",
    "            return content\n",
    "    \n",
    "    async def afetch(self, url: str) -> str:\n",
    "        \"\"\"URLì—ì„œ ë¬¸ì„œë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ê°€ì ¸ì˜´\"\"\"\n",
    "        # ìƒëŒ€ URL ì²˜ë¦¬\n",
    "        if not url.startswith('http'):\n",
    "            url = urljoin(self.base_url, url)\n",
    "        \n",
    "        # ìºì‹œ í™•ì¸\n",
    "        if url in self._cache:\n",
    "            return self._cache[url]\n",
    "        \n",
    "        async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:\n",
    "            response = await client.get(url)\n",
    "            response.raise_for_status()\n",
    "            content = response.text\n",
    "            self._cache[url] = content\n",
    "            return content\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_links(content: str) -> list[dict[str, str]]:\n",
    "        \"\"\"ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ ì—ì„œ ë§í¬ ì¶”ì¶œ\"\"\"\n",
    "        links = []\n",
    "        # ë§ˆí¬ë‹¤ìš´ ë§í¬ íŒ¨í„´: [text](url)\n",
    "        pattern = r'\\[([^\\]]+)\\]\\(([^)]+)\\)'\n",
    "        for match in re.finditer(pattern, content):\n",
    "            title, url = match.groups()\n",
    "            # ë‚´ë¶€ ì•µì»¤ ë§í¬ ì œì™¸\n",
    "            if not url.startswith('#'):\n",
    "                links.append({'title': title, 'url': url})\n",
    "        return links\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Tool ì •ì˜\n",
    "# ==============================================================================\n",
    "\n",
    "def create_llms_txt_tools(llms_txt_url: str):\n",
    "    \"\"\"llms.txt ê¸°ë°˜ tools ìƒì„±\"\"\"\n",
    "    \n",
    "    # ê³µìœ  ì¸ìŠ¤í„´ìŠ¤\n",
    "    loader = LLMSTxtLoader(llms_txt_url)\n",
    "    fetcher = DocumentFetcher(base_url=llms_txt_url.rsplit('/', 1)[0] + '/')\n",
    "    \n",
    "    # ì´ˆê¸° ë¡œë“œ\n",
    "    loader.load()\n",
    "    \n",
    "    @tool\n",
    "    def search_docs(keyword: str) -> str:\n",
    "        \"\"\"ì¸ë±ìŠ¤ì—ì„œ í‚¤ì›Œë“œë¡œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "        \n",
    "        Args:\n",
    "            keyword: ê²€ìƒ‰í•  í‚¤ì›Œë“œ (í•œê¸€ ë˜ëŠ” ì˜ì–´)\n",
    "        \n",
    "        Returns:\n",
    "            ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡ (ë¬¸ì„œ ì œëª©, URL, ì„¤ëª…)\n",
    "        \"\"\"\n",
    "        results = loader.search(keyword)\n",
    "        \n",
    "        if not results:\n",
    "            return f\"'{keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.\"\n",
    "        \n",
    "        lines = [f\"'{keyword}' ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê±´):\\n\"]\n",
    "        for r in results:\n",
    "            desc = f\" - {r['description']}\" if r['description'] else \"\"\n",
    "            lines.append(f\"- [{r['title']}]({r['url']}){desc}\")\n",
    "            lines.append(f\"  ì„¹ì…˜: {r['section']}\")\n",
    "        \n",
    "        return '\\n'.join(lines)\n",
    "    \n",
    "    @tool\n",
    "    def fetch_document(url: str) -> str:\n",
    "        \"\"\"URLì—ì„œ ë¬¸ì„œ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ìƒì„¸ ì •ë³´ê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "        \n",
    "        Args:\n",
    "            url: ê°€ì ¸ì˜¬ ë¬¸ì„œì˜ URL (search_docs ê²°ê³¼ì—ì„œ ì–»ì€ URL)\n",
    "        \n",
    "        Returns:\n",
    "            ë¬¸ì„œ ë‚´ìš© (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = fetcher.fetch(url)\n",
    "            \n",
    "            # ë„ˆë¬´ ê¸´ ê²½ìš° ìë¥´ê¸° (í† í° ì ˆì•½)\n",
    "            if len(content) > 15000:\n",
    "                content = content[:15000] + \"\\n\\n... (ë¬¸ì„œê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. í•„ìš”í•œ ë¶€ë¶„ë§Œ í™•ì¸í•˜ì„¸ìš”)\"\n",
    "            \n",
    "            # ì¶”ê°€ ë§í¬ê°€ ìˆìœ¼ë©´ ì•Œë ¤ì£¼ê¸°\n",
    "            links = fetcher.extract_links(content)\n",
    "            if links:\n",
    "                content += f\"\\n\\n---\\nğŸ“ ì´ ë¬¸ì„œì—ì„œ ë°œê²¬ëœ ë§í¬ ({len(links)}ê°œ):\\n\"\n",
    "                for link in links[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ\n",
    "                    content += f\"- [{link['title']}]({link['url']})\\n\"\n",
    "                if len(links) > 10:\n",
    "                    content += f\"... ì™¸ {len(links) - 10}ê°œ ë”\"\n",
    "            \n",
    "            return content\n",
    "        except Exception as e:\n",
    "            return f\"ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
    "    \n",
    "    @tool\n",
    "    def get_doc_index() -> str:\n",
    "        \"\"\"ì „ì²´ ë¬¸ì„œ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì–´ë–¤ ë¬¸ì„œë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "        \n",
    "        Returns:\n",
    "            ì „ì²´ ë¬¸ì„œ ì¸ë±ìŠ¤ (ì„¹ì…˜ë³„ ëª©ë¡)\n",
    "        \"\"\"\n",
    "        return loader.get_summary()\n",
    "    \n",
    "    return [search_docs, fetch_document, get_doc_index], loader\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# System Prompt ìƒì„±\n",
    "# ==============================================================================\n",
    "\n",
    "def create_system_prompt(loader: LLMSTxtLoader) -> str:\n",
    "    \"\"\"llms.txt ì¸ë±ìŠ¤ë¥¼ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "    \n",
    "    index_summary = loader.get_summary()\n",
    "    \n",
    "    return f\"\"\"ë‹¹ì‹ ì€ llms.txt ê¸°ë°˜ API ë¬¸ì„œ ê°€ì´ë“œ ì „ë¬¸ê°€ ì±—ë´‡ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ì—­í• \n",
    "ì‚¬ìš©ìê°€ APIì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´, ë¬¸ì„œ ì¸ë±ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  í•„ìš”í•œ ìƒì„¸ ë¬¸ì„œë¥¼ ê°€ì ¸ì™€ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "## Tool ì‚¬ìš© ê°€ì´ë“œ\n",
    "\n",
    "### 1. search_docs\n",
    "- í‚¤ì›Œë“œë¡œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©\n",
    "- í•œê¸€/ì˜ì–´ ëª¨ë‘ ê°€ëŠ¥\n",
    "- ì˜ˆ: \"ì¸ì¦\", \"ì¡°íšŒ\", \"JWT\", \"API\"\n",
    "\n",
    "### 2. fetch_document  \n",
    "- ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì–»ì€ URLë¡œ ìƒì„¸ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¬ ë•Œ ì‚¬ìš©\n",
    "- ë¬¸ì„œ ì•ˆì— ì¶”ê°€ ë§í¬ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ\n",
    "\n",
    "### 3. get_doc_index\n",
    "- ì „ì²´ ë¬¸ì„œ ëª©ë¡ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©\n",
    "\n",
    "## ë‹µë³€ ì›ì¹™\n",
    "1. **ì •í™•ì„±**: ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€\n",
    "2. **ê°„ê²°ì„±**: í•µì‹¬ë§Œ ì „ë‹¬\n",
    "3. **ì‹¤ìš©ì„±**: API ì‚¬ìš© ì˜ˆì‹œ í¬í•¨ ì‹œ ë„ì›€ë¨\n",
    "\n",
    "## ë¬¸ì„œ ì¸ë±ìŠ¤ (ì°¸ê³ ìš©)\n",
    "{index_summary}\n",
    "\n",
    "## ì£¼ì˜ì‚¬í•­\n",
    "- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”\n",
    "- í•„ìš” ì‹œ ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”\n",
    "- ë§í¬ ì•ˆì˜ ë§í¬ë„ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Agent ìƒì„±\n",
    "# ==============================================================================\n",
    "\n",
    "def create_llms_txt_agent(\n",
    "    llms_txt_url: str = \"https://example.com/llms.txt\",  # TODO: ì‹¤ì œ llms.txt URLë¡œ ë³€ê²½í•˜ì„¸ìš”\n",
    "    model_name: str = \"databricks-gpt-5-2\",\n",
    "    system_prompt: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"llms.txt ê¸°ë°˜ Langchain Agent ìƒì„± (ë™ê¸° ë²„ì „)\n",
    "    \n",
    "    Args:\n",
    "        llms_txt_url: llms.txt íŒŒì¼ URL\n",
    "        model_name: Databricks Foundation Model ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„\n",
    "        system_prompt: ì»¤ìŠ¤í…€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Noneì´ë©´ ìë™ ìƒì„±)\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Langchain Agent\n",
    "    \"\"\"\n",
    "    \n",
    "    # ëª¨ë¸ ì„¤ì •\n",
    "    model = ChatDatabricks(endpoint=model_name)\n",
    "    \n",
    "    # Tools ë° Loader ìƒì„±\n",
    "    tools, loader = create_llms_txt_tools(llms_txt_url)\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì¸ë±ìŠ¤ í¬í•¨)\n",
    "    final_prompt = system_prompt or create_system_prompt(loader)\n",
    "    \n",
    "    # Agent ìƒì„±\n",
    "    return create_agent(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        system_prompt=final_prompt\n",
    "    )\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_default_llms_txt_agent():\n",
    "    \"\"\"ê¸°ë³¸ Agent ìºì‹± (ì‹±ê¸€í†¤)\"\"\"\n",
    "    return create_llms_txt_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48233ad2-21d4-4abd-9f50-7980ad105640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile langchain_sync_wrapper_agent.py\n",
    "\"\"\"\n",
    "Langchain Agent Wrapper (ë™ê¸° ë²„ì „)\n",
    "\n",
    "MLflow ResponsesAgentë¥¼ ë˜í•‘í•˜ì—¬ Langchain Agentë¥¼ \n",
    "MLflowì˜ predict/predict_stream ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ëª¨ë“ˆì€ Langchainì˜ ë™ê¸° ë°©ì‹ í‘œì¤€ ì˜ˆì œì…ë‹ˆë‹¤.\n",
    "stream_mode=\"messages\"ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "from typing import Any, Generator\n",
    "import json\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    "    to_chat_completions_input,\n",
    "    output_to_responses_items_stream,\n",
    ")\n",
    "\n",
    "from langchain_core.messages.ai import AIMessageChunk\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "\n",
    "from langchain_sync_agent import create_llms_txt_agent\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "class LangchainSyncResponsesAgent(ResponsesAgent):\n",
    "    \"\"\"Langchain Agent - ë™ê¸° ë²„ì „ (í† í° ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.agent = create_llms_txt_agent()\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        \"\"\"ì „ì²´ ì‘ë‹µì„ í•œë²ˆì— ë°˜í™˜ (ë™ê¸°)\n",
    "        \n",
    "        predict_streamì„ í˜¸ì¶œí•˜ì—¬ ëª¨ë“  ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸ë¥¼ ìˆ˜ì§‘í•œ í›„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        \"\"\"\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\" or event.type == \"error\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(\n",
    "            output=outputs, \n",
    "            custom_outputs=request.custom_inputs\n",
    "        )\n",
    "\n",
    "    def predict_stream(\n",
    "        self, request: ResponsesAgentRequest\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        \"\"\"ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° - stream_mode='messages'ë¡œ í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°\n",
    "        \n",
    "        Langchainì˜ ë™ê¸° ë°©ì‹ í‘œì¤€ íŒ¨í„´ì…ë‹ˆë‹¤.\n",
    "        stream_mode=\"messages\"ëŠ” íŠœí”Œ (message_chunk, metadata) í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        \"\"\"\n",
    "        \n",
    "        # OpenAI í˜•ì‹ ë©”ì‹œì§€ë¥¼ LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "        cc_msgs = to_chat_completions_input([i.model_dump() for i in request.input])\n",
    "        \n",
    "        # stream_mode=\"messages\"ë¡œ í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°\n",
    "        # ë°˜í™˜ í˜•ì‹: (message_chunk, metadata) íŠœí”Œ\n",
    "        for msg, metadata in self.agent.stream(\n",
    "            {\"messages\": cc_msgs}, \n",
    "            stream_mode=\"messages\"\n",
    "        ):\n",
    "            try:\n",
    "                if isinstance(msg, AIMessageChunk):\n",
    "                    # í…ìŠ¤íŠ¸ ì½˜í…ì¸ ê°€ ìˆê³ , tool_callsê°€ ì—†ì„ ë•Œ (ìµœì¢… ë‹µë³€)\n",
    "                    if msg.content and not msg.tool_calls:\n",
    "                        yield ResponsesAgentStreamEvent(\n",
    "                            **self.create_text_delta(\n",
    "                                delta=msg.content, \n",
    "                                item_id=msg.id or str(uuid4())\n",
    "                            ),\n",
    "                        )\n",
    "                \n",
    "                elif isinstance(msg, ToolMessage):\n",
    "                    # Tool ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°\n",
    "                    for item in output_to_responses_items_stream([msg]):\n",
    "                        yield item\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"DEBUG: Error in stream handling: {e}\")\n",
    "                print(f\"DEBUG: msg type: {type(msg)}, metadata: {metadata}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# MLflow ëª¨ë¸ ë“±ë¡\n",
    "# ==============================================================================\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangchainSyncResponsesAgent()\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b99e9e1c-186b-46dd-b8b4-c25d09138f57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent í…ŒìŠ¤íŠ¸\n",
    "\n",
    "Agentì™€ ìƒí˜¸ì‘ìš©í•˜ì—¬ ì¶œë ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. `ResponsesAgent` ë‚´ì—ì„œ ë©”ì„œë“œë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì¶”ì í–ˆê¸° ë•Œë¬¸ì—, Agentê°€ ìˆ˜í–‰í•˜ëŠ” ê° ë‹¨ê³„ì˜ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Langchainì„ í†µí•œ LLM í˜¸ì¶œì€ autologgingì— ì˜í•´ ìë™ìœ¼ë¡œ ì¶”ì ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ì˜ ì˜ˆì‹œ ì…ë ¥ì„ ì‹¤ì œ ë„ë©”ì¸ì— ë§ëŠ” ì˜ˆì‹œë¡œ ë³€ê²½í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4db424d-892b-4259-8baf-891d49d9cd93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6555e707-d303-4f36-b284-83de80beb367",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_sync_wrapper_agent import AGENT\n",
    "\n",
    "# ë‹¨ì¼ ì‘ë‹µ í…ŒìŠ¤íŠ¸ (ë¹„ìŠ¤íŠ¸ë¦¬ë°)\n",
    "AGENT.predict(\n",
    "    {\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"}], \n",
    "        \"custom_inputs\": {\"session_id\": \"test-session-123\"}\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e282ce4e-b1cf-40fc-aac1-de45812d3f8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_sync_wrapper_agent import AGENT\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í…ŒìŠ¤íŠ¸ (ìƒì„¸ ì¶œë ¥)\n",
    "for chunk in AGENT.predict_stream(\n",
    "    {\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"ì¸ì¦ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"}], \n",
    "        \"custom_inputs\": {\"session_id\": \"test-session-123\"}\n",
    "    },\n",
    "):\n",
    "    if chunk.type != 'response.output_item.done':\n",
    "        print(\"===============\\n\")\n",
    "    print(f\"{chunk=}\\n\")\n",
    "    print(chunk.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7e0ed52-347d-42ab-ac51-6cd8a6623a73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Agentë¥¼ MLflow ëª¨ë¸ë¡œ ë¡œê¹…\n",
    "\n",
    "ë°°í¬ ì‹œ ìë™ ì¸ì¦ íŒ¨ìŠ¤ìŠ¤ë£¨ë¥¼ ìœ„í•´ Databricks ë¦¬ì†ŒìŠ¤ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **TODO**: Unity Catalog í•¨ìˆ˜ê°€ [Vector Search ì¸ë±ìŠ¤](https://docs.databricks.com/generative-ai/agent-framework/unstructured-retrieval-tools.html)ë¥¼ ì¿¼ë¦¬í•˜ê±°ë‚˜ [ì™¸ë¶€ í•¨ìˆ˜](https://docs.databricks.com/generative-ai/agent-framework/external-connection-tools.html)ë¥¼ í™œìš©í•˜ëŠ” ê²½ìš°, í•´ë‹¹ Vector Search ì¸ë±ìŠ¤ì™€ UC ì—°ê²° ê°ì²´ë¥¼ ë¦¬ì†ŒìŠ¤ë¡œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ê³µì‹ ë¬¸ì„œ](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n",
    "\n",
    "Agent ì½”ë“œë¥¼ Python íŒŒì¼ì—ì„œ ë¡œê¹…í•©ë‹ˆë‹¤. [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code) ì°¸ê³ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16716a86-a458-4485-9089-1849b4a8f286",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 12"
    }
   },
   "outputs": [],
   "source": [
    "# ë°°í¬ ì‹œ ìë™ ì¸ì¦ íŒ¨ìŠ¤ìŠ¤ë£¨ë¥¼ ìœ„í•œ Databricks ë¦¬ì†ŒìŠ¤ ì„¤ì •\n",
    "import mlflow\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint, DatabricksUCConnection\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "# TODO: í™˜ê²½ì— ë§ê²Œ ì•„ë˜ ì„¤ì •ê°’ì„ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "LLM_ENDPOINT_NAME = \"databricks-gpt-5-2\"  # ì‚¬ìš©í•  LLM ì—”ë“œí¬ì¸íŠ¸\n",
    "\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "]\n",
    "\n",
    "# ì…ë ¥ ì˜ˆì‹œ (ëª¨ë¸ ì‹œê·¸ë‹ˆì²˜ ì¶”ë¡ ìš©)\n",
    "input_example = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "        }\n",
    "    ],\n",
    "    \"custom_inputs\": {\n",
    "        \"session_id\": \"test-session-123\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# MLflowì— Agent ë¡œê¹…\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"langchain_sync_agent\",\n",
    "        python_model=\"langchain_sync_wrapper_agent.py\",\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            \"databricks-langchain\",\n",
    "            \"backoff\",\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "        ],\n",
    "        code_paths=[\n",
    "            \"langchain_sync_agent.py\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d006dd14-e9cc-4e68-aa46-69393e7af04c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## [Agent Evaluation](https://docs.databricks.com/mlflow3/genai/eval-monitor)ìœ¼ë¡œ Agent í‰ê°€\n",
    "\n",
    "í‰ê°€ ë°ì´í„°ì…‹ì˜ ìš”ì²­ì´ë‚˜ ì˜ˆìƒ ì‘ë‹µì„ ìˆ˜ì •í•˜ê³ , Agentë¥¼ ë°˜ë³µ ê°œì„ í•˜ë©´ì„œ í‰ê°€ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. MLflowë¥¼ í™œìš©í•˜ì—¬ ê³„ì‚°ëœ í’ˆì§ˆ ë©”íŠ¸ë¦­ì„ ì¶”ì í•©ë‹ˆë‹¤.\n",
    "\n",
    "[ì‚¬ì „ ì •ì˜ëœ LLM ìŠ¤ì½”ì–´ëŸ¬](https://docs.databricks.com/mlflow3/genai/eval-monitor/predefined-judge-scorers)ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, [ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­](https://docs.databricks.com/mlflow3/genai/eval-monitor/custom-scorers)ì„ ì¶”ê°€í•˜ì—¬ Agentë¥¼ í‰ê°€í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08ff3f52-99c1-49cc-9e47-dfb4707701cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 14"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Safety, RetrievalRelevance, RetrievalGroundedness\n",
    "\n",
    "# í‰ê°€ ë°ì´í„°ì…‹ ì •ì˜\n",
    "# TODO: ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ ì§ˆë¬¸ê³¼ ì˜ˆìƒ ì‘ë‹µì„ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"ì¸ì¦ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "# Agent í‰ê°€ ì‹¤í–‰\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda input: AGENT.predict({\"input\": input, \"custom_inputs\": {\"session_id\": \"evaluation-session\"}}),\n",
    "    scorers=[RelevanceToQuery(), Safety()],  # í•„ìš”ì— ë”°ë¼ ìŠ¤ì½”ì–´ëŸ¬ ì¶”ê°€\n",
    ")\n",
    "\n",
    "# MLflow UIì—ì„œ í‰ê°€ ê²°ê³¼ í™•ì¸ (ì½˜ì†” ì¶œë ¥ ì°¸ì¡°)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab5fabfc-a657-4006-8330-134b13d9e36a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ë°°í¬ ì „ Agent ê²€ì¦\n",
    "\n",
    "Agentë¥¼ ë“±ë¡í•˜ê³  ë°°í¬í•˜ê¸° ì „ì— [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) APIë¥¼ í†µí•´ ì‚¬ì „ ë°°í¬ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ê³µì‹ ë¬¸ì„œ](https://docs.databricks.com/machine-learning/model-serving/model-serving-debug.html#validate-inputs)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3acdcf0-461e-4071-bd9f-ffdf77deacac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ë°°í¬ ì „ ê²€ì¦ - ë¡œê¹…ëœ ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ”ì§€ í™•ì¸\n",
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/langchain_sync_agent\",\n",
    "    input_data={\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"}], \n",
    "        \"custom_inputs\": {\"session_id\": \"validation-session\"}\n",
    "    },\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e15b7c0-2e96-4efe-841f-1f0d4210db06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Unity Catalogì— ëª¨ë¸ ë“±ë¡\n",
    "\n",
    "ì•„ë˜ì˜ `catalog`, `schema`, `model_name`ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ MLflow ëª¨ë¸ì„ Unity Catalogì— ë“±ë¡í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4b97dfc-4218-4341-9db2-594de88caac9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: Unity Catalog ëª¨ë¸ì˜ catalog, schema, model_nameì„ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "catalog = \"ml\"\n",
    "schema = \"default\"\n",
    "model_name = \"langchain-sync-agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# Unity Catalogì— ëª¨ë¸ ë“±ë¡\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94c921e6-2f62-4add-8254-d703c5325749",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent ë°°í¬\n",
    "\n",
    "Agentë¥¼ Databricks Model Serving ì—”ë“œí¬ì¸íŠ¸ë¡œ ë°°í¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac63b207-a575-43c1-b73f-a9e0856a5597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# ì°¸ê³ : scale_to_zero=Trueë¥¼ ì „ë‹¬í•˜ë©´ ë¹„ìš© ì ˆê°ì„ ìœ„í•œ ìŠ¤ì¼€ì¼ íˆ¬ ì œë¡œê°€ í™œì„±í™”ë©ë‹ˆë‹¤.\n",
    "# í”„ë¡œë•ì…˜ ì›Œí¬ë¡œë“œì—ëŠ” ê¶Œì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ìŠ¤ì¼€ì¼ ì œë¡œ ìƒíƒœì—ì„œëŠ” ìš©ëŸ‰ì´ ë³´ì¥ë˜ì§€ ì•ŠìŒ).\n",
    "# ìŠ¤ì¼€ì¼ ì œë¡œ ìƒíƒœì˜ ì—”ë“œí¬ì¸íŠ¸ëŠ” ë‹¤ì‹œ ìŠ¤ì¼€ì¼ì—…í•˜ëŠ” ë™ì•ˆ ì‘ë‹µ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME, \n",
    "    uc_registered_model_info.version, \n",
    "    tags={\"endpointSource\": \"local_development\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1171890-c406-4b52-9253-e19f7357cab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "Agentê°€ ë°°í¬ë˜ë©´ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "- **AI Playgroundì—ì„œ í…ŒìŠ¤íŠ¸**: ì¶”ê°€ ê²€ì¦ì„ ìœ„í•´ ëŒ€í™”í˜•ìœ¼ë¡œ Agent í…ŒìŠ¤íŠ¸\n",
    "- **í”¼ë“œë°± ìˆ˜ì§‘**: ì¡°ì§ ë‚´ ì „ë¬¸ê°€(SME)ì™€ Agent ê³µìœ í•˜ì—¬ í”¼ë“œë°± ìˆ˜ì§‘\n",
    "- **í”„ë¡œë•ì…˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì— í†µí•©**: ì‹¤ì œ ì„œë¹„ìŠ¤ì— Agent ì„ë² ë”©\n",
    "\n",
    "ìì„¸í•œ ë‚´ìš©ì€ [ê³µì‹ ë¬¸ì„œ](https://docs.databricks.com/generative-ai/deploy-agent.html)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7131cf6-6ad8-4035-a335-9c09086f1f2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "llms_txt_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
