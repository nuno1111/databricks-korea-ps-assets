{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce8129a-d71c-4a3c-acbd-a5822178a94b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Langchain Agent with llms.txt (ë™ê¸° ë²„ì „)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **Langchain**ê³¼ **Databricks**ë¥¼ í™œìš©í•˜ì—¬ llms.txt ê¸°ë°˜ Tool-calling Agentë¥¼ êµ¬í˜„í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.\n",
    "\n",
    "## ë™ê¸°(Sync) ë²„ì „ì´ë€?\n",
    "\n",
    "> âœ… **Langchain ë™ê¸° ë°©ì‹ì˜ í‘œì¤€ ì˜ˆì œì…ë‹ˆë‹¤.** Langchainì˜ `stream_mode=\"messages\"`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ê¸° ë°©ì‹ìœ¼ë¡œ í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ë¹„ë™ê¸° ì²˜ë¦¬ê°€ í•„ìš” ì—†ëŠ” í™˜ê²½ì—ì„œ ë” ê°„ë‹¨í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## llms.txt ì ‘ê·¼ ë°©ì‹\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ MCP ëŒ€ì‹  **llms.txt** íŒŒì¼ì„ í™œìš©í•˜ëŠ” ê²½ëŸ‰ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
    "- MCPë³´ë‹¤ ê°€ë³ê³  ì„¤ì •ì´ ê°„ë‹¨\n",
    "- RAGë³´ë‹¤ ì •í™•í•œ ë¬¸ì„œ ì°¸ì¡°\n",
    "- llms.txtë¥¼ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ ë¬¸ì„œë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜´\n",
    "\n",
    "## ì´ ë…¸íŠ¸ë¶ì—ì„œ ë‹¤ë£¨ëŠ” ë‚´ìš©\n",
    "\n",
    "- Langchain + Databricks Foundation Model APIë¥¼ í™œìš©í•œ Agent êµ¬í˜„\n",
    "- llms.txt ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ë° í˜ì¹­ ë„êµ¬ êµ¬í˜„\n",
    "- MLflowì˜ `ResponsesAgent`ë¥¼ ì‚¬ìš©í•œ ë˜í¼ í´ë˜ìŠ¤ ì‘ì„±\n",
    "- Agent ì¶œë ¥ í…ŒìŠ¤íŠ¸ ë° ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬\n",
    "- Mosaic AI Agent Evaluationì„ í†µí•œ í‰ê°€\n",
    "- Unity Catalogì— ëª¨ë¸ ë“±ë¡ ë° ë°°í¬\n",
    "\n",
    "## ì‹¤í–‰ í™˜ê²½\n",
    "\n",
    "- Databricks Serverless ë˜ëŠ” DBR 17 ì´ìƒ í´ëŸ¬ìŠ¤í„°\n",
    "- Unity Catalog í™œì„±í™” í•„ìˆ˜\n",
    "\n",
    "## ì‚¬ì „ ìš”êµ¬ì‚¬í•­\n",
    "\n",
    "- ì´ ë…¸íŠ¸ë¶ì˜ ëª¨ë“  `TODO` í•­ëª©ì„ í™•ì¸í•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fa5e662-e6e3-443b-9da9-2d7a6b824a9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq backoff databricks-langchain uv databricks-agents mlflow-skinny[databricks]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad62dac7-b239-4c0a-8614-1de9e420eee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent ì½”ë“œ ì •ì˜\n",
    "\n",
    "ì•„ë˜ì—ì„œ Agent ì½”ë“œë¥¼ ë‹¨ì¼ ì…€ì— ì •ì˜í•©ë‹ˆë‹¤. `%%writefile` ë§¤ì§ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ Python íŒŒì¼ë¡œ ì €ì¥í•˜ë©´, ì´í›„ MLflow ë¡œê¹… ë° ë°°í¬ ì‹œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
    "- **LLMSTxtLoader**: llms.txt íŒŒì¼ ë¡œë“œ ë° ì¸ë±ìŠ¤ íŒŒì‹±\n",
    "- **DocumentFetcher**: URLì—ì„œ ë¬¸ì„œ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ìœ í‹¸ë¦¬í‹°\n",
    "- **Tool ì •ì˜**: search_docs, fetch_document, get_doc_index\n",
    "- **ChatDatabricks**: Databricks Foundation Model API ì—°ë™\n",
    "\n",
    "Agentì— ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ë„êµ¬ ì˜ˆì œëŠ” [ê³µì‹ ë¬¸ì„œ](https://docs.databricks.com/generative-ai/agent-framework/agent-tool.html)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ca0ae6-8707-4a35-926f-d9c64fee7f20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile langchain_sync_agent.py\n",
    "\n",
    "import httpx\n",
    "from functools import lru_cache\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# llms.txt ë¡œë”\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def load_llms_txt(url: str) -> str:\n",
    "    \"\"\"llms.txt íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ì›ë¬¸ ë°˜í™˜\"\"\"\n",
    "    with httpx.Client(timeout=10) as client:\n",
    "        response = client.get(url)\n",
    "        response.raise_for_status()\n",
    "        content = response.text\n",
    "        return re.sub(r\"^# .+\", \"# ë¹—ì¸ API ë¬¸ì„œ ì¸ë±ìŠ¤\", content, count=1)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ë¬¸ì„œ fetcher í•¨ìˆ˜\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def fetch_document_content(url: str, base_url: str = \"\") -> str:\n",
    "    \"\"\"URLì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´ (ìºì‹± í¬í•¨)\n",
    "\n",
    "    Args:\n",
    "        url: ê°€ì ¸ì˜¬ ë¬¸ì„œ URL\n",
    "        base_url: ìƒëŒ€ URL ì²˜ë¦¬ë¥¼ ìœ„í•œ ê¸°ë³¸ URL\n",
    "\n",
    "    Returns:\n",
    "        ë¬¸ì„œ ë‚´ìš©\n",
    "    \"\"\"\n",
    "    # URL ì •ê·œí™”\n",
    "    if not url.startswith(\"http\"):\n",
    "        if base_url and not base_url.endswith(\"/\"):\n",
    "            base_url = base_url.rsplit(\"/\", 1)[0] + \"/\"\n",
    "        url = urljoin(base_url, url)\n",
    "\n",
    "    with httpx.Client(timeout=10, follow_redirects=True) as client:\n",
    "        response = client.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "\n",
    "\n",
    "def extract_links(content: str) -> list[dict[str, str]]:\n",
    "    \"\"\"ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ ì—ì„œ ë§í¬ ì¶”ì¶œ\n",
    "\n",
    "    Args:\n",
    "        content: ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ë‚´ìš©\n",
    "\n",
    "    Returns:\n",
    "        ë§í¬ ëª©ë¡ (title, url)\n",
    "    \"\"\"\n",
    "    links = []\n",
    "    pattern = r\"\\[([^\\]]+)\\]\\(([^)]+)\\)\"\n",
    "    for match in re.finditer(pattern, content):\n",
    "        title, url = match.groups()\n",
    "        if not url.startswith(\"#\"):  # ë‚´ë¶€ ì•µì»¤ ë§í¬ ì œì™¸\n",
    "            links.append({\"title\": title, \"url\": url})\n",
    "    return links\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Tool ì •ì˜\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def create_llms_txt_tools(llms_txt_url: str):\n",
    "    \"\"\"llms.txt ê¸°ë°˜ tools ìƒì„±\"\"\"\n",
    "\n",
    "    # llms.txt ë¡œë“œ\n",
    "    llms_txt_content = load_llms_txt(llms_txt_url)\n",
    "\n",
    "    @tool\n",
    "    def fetch_document(url: str) -> str:\n",
    "        \"\"\"URLì—ì„œ ë¬¸ì„œ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "\n",
    "        Args:\n",
    "            url: ê°€ì ¸ì˜¬ ë¬¸ì„œì˜ URL\n",
    "\n",
    "        Returns:\n",
    "            ë¬¸ì„œ ë‚´ìš© (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = fetch_document_content(url, base_url=llms_txt_url)\n",
    "\n",
    "            # ì¶”ê°€ ë§í¬ ì •ë³´ ì œê³µ\n",
    "            links = extract_links(content)\n",
    "            if links:\n",
    "                content += f\"\\n\\n---\\nğŸ“ ì´ ë¬¸ì„œì˜ ë§í¬ ({len(links)}ê°œ):\\n\"\n",
    "                for link in links:\n",
    "                    content += f\"- [{link['title']}]({link['url']})\\n\"\n",
    "\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            return f\"ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "    return [fetch_document], llms_txt_content\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# System Prompt ìƒì„±\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def create_system_prompt(llms_txt_content: str) -> str:\n",
    "    \"\"\"llms.txt ì›ë¬¸ì„ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "\n",
    "    return f\"\"\"ë‹¹ì‹ ì€ ë¹—ì¸ API ê°€ì´ë“œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ì—­í• \n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ëŠ” ë¬¸ì„œë¥¼ ì°¾ì•„ì„œ fetch_document toolë¡œ ê°€ì ¸ì˜¨ ë’¤ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ ëª©ë¡\n",
    "{llms_txt_content}\n",
    "\n",
    "## ë‹µë³€ ë°©ë²•\n",
    "1. ìœ„ ë¬¸ì„œ ëª©ë¡ì—ì„œ ê´€ë ¨ URLì„ ì°¾ìŠµë‹ˆë‹¤\n",
    "2. fetch_document(url)ë¡œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
    "3. ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤\n",
    "4. ì¶”ê°€ ë§í¬ê°€ í•„ìš”í•˜ë©´ í•´ë‹¹ ë¬¸ì„œë„ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
    "\n",
    "## ì£¼ì˜ì‚¬í•­\n",
    "- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”\n",
    "- í•„ìš” ì‹œ ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”\n",
    "- ë§í¬ ì•ˆì˜ ë§í¬ë„ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Agent ìƒì„±\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def create_llms_txt_agent(\n",
    "    llms_txt_url: str = \"https://examlple/llms.txt\",\n",
    "    model_name: str = \"databricks-gpt-5-2\",\n",
    "    system_prompt: str | None = None,\n",
    "):\n",
    "    \"\"\"llms.txt ê¸°ë°˜ Agent ìƒì„±\n",
    "\n",
    "    Args:\n",
    "        llms_txt_url: llms.txt íŒŒì¼ URL\n",
    "        model_name: ì‚¬ìš©í•  LLM ëª¨ë¸ ì´ë¦„\n",
    "        system_prompt: ì»¤ìŠ¤í…€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Noneì´ë©´ ìë™ ìƒì„±)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Agent\n",
    "    \"\"\"\n",
    "\n",
    "    # ëª¨ë¸ ì„¤ì •\n",
    "    model = ChatDatabricks(endpoint=model_name)\n",
    "\n",
    "    # Tools ë° llms.txt ì›ë¬¸ ë¡œë“œ\n",
    "    tools, llms_txt_content = create_llms_txt_tools(llms_txt_url)\n",
    "\n",
    "    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    final_prompt = system_prompt or create_system_prompt(llms_txt_content)\n",
    "\n",
    "    # Agent ìƒì„±\n",
    "    return create_agent(model=model, tools=tools, system_prompt=final_prompt)\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_default_llms_txt_agent():\n",
    "    \"\"\"ê¸°ë³¸ Agent ìºì‹± (ì‹±ê¸€í†¤)\"\"\"\n",
    "    return create_llms_txt_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48233ad2-21d4-4abd-9f50-7980ad105640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile langchain_sync_wrapper_agent.py\n",
    "\"\"\"\n",
    "Langchain Agent Wrapper (ë™ê¸° ë²„ì „)\n",
    "\n",
    "MLflow ResponsesAgentë¥¼ ë˜í•‘í•˜ì—¬ Langchain Agentë¥¼ \n",
    "MLflowì˜ predict/predict_stream ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ëª¨ë“ˆì€ Langchainì˜ ë™ê¸° ë°©ì‹ í‘œì¤€ ì˜ˆì œì…ë‹ˆë‹¤.\n",
    "stream_mode=\"messages\"ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "from typing import Any, Generator\n",
    "import json\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    "    to_chat_completions_input,\n",
    "    output_to_responses_items_stream,\n",
    ")\n",
    "\n",
    "from langchain_core.messages.ai import AIMessageChunk\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "\n",
    "from langchain_sync_agent import create_llms_txt_agent\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "class LangchainSyncResponsesAgent(ResponsesAgent):\n",
    "    \"\"\"Langchain Agent - ë™ê¸° ë²„ì „ (í† í° ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.agent = create_llms_txt_agent()\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        \"\"\"ì „ì²´ ì‘ë‹µì„ í•œë²ˆì— ë°˜í™˜ (ë™ê¸°)\"\"\"\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\" or event.type == \"error\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(\n",
    "            output=outputs,\n",
    "            custom_outputs=request.custom_inputs\n",
    "        )\n",
    "\n",
    "    def predict_stream(\n",
    "        self, request: ResponsesAgentRequest\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        \"\"\"ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°\n",
    "\n",
    "        stream_mode=[\"updates\", \"messages\"]ë¥¼ ì‚¬ìš©í•´ì„œ:\n",
    "        - \"messages\": ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ í† í° ìŠ¤íŠ¸ë¦¬ë° (ì‚¬ìš©ì ê²½í—˜)\n",
    "        - \"updates\": ì™„ì „í•œ ë©”ì‹œì§€ (AIMessage with tool_calls, ToolMessage) (íˆìŠ¤í† ë¦¬ ì €ì¥)\n",
    "\n",
    "        ì´ë ‡ê²Œ í•˜ë©´ Playground ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì™„ì „í•œ AIMessage (tool_calls í¬í•¨)ê°€ ì €ì¥ë˜ì–´\n",
    "        ë‹¤ìŒ í„´ì—ì„œ ToolMessageê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬ë¨\n",
    "        \"\"\"\n",
    "\n",
    "        cc_msgs = to_chat_completions_input([i.model_dump() for i in request.input])\n",
    "\n",
    "        for event in self.agent.stream(\n",
    "            {\"messages\": cc_msgs},\n",
    "            stream_mode=[\"updates\", \"messages\"],\n",
    "        ):\n",
    "            try:\n",
    "                mode = event[0]\n",
    "                data = event[1]\n",
    "\n",
    "                # ============================================================\n",
    "                # \"messages\" ëª¨ë“œ: ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¸íƒ€ ìŠ¤íŠ¸ë¦¬ë°ë§Œ\n",
    "                # ============================================================\n",
    "                if mode == \"messages\":\n",
    "                    msg, metadata = data  # messages ëª¨ë“œëŠ” (msg, metadata) íŠœí”Œ\n",
    "\n",
    "                    if isinstance(msg, AIMessageChunk) and msg.content:\n",
    "                        yield ResponsesAgentStreamEvent(\n",
    "                            **self.create_text_delta(\n",
    "                                delta=msg.content,\n",
    "                                item_id=msg.id or str(uuid4())\n",
    "                            ),\n",
    "                        )\n",
    "\n",
    "                # ============================================================\n",
    "                # \"updates\" ëª¨ë“œ: ì™„ì „í•œ tool call/result ë©”ì‹œì§€ë§Œ\n",
    "                # ============================================================\n",
    "                elif mode == \"updates\":\n",
    "                    # updatesëŠ” {'node_name': {'messages': [...]}} í˜•íƒœ\n",
    "                    # ì „ì²´ messages ë°°ì—´ì„ output_to_responses_items_stream()ì— ì „ë‹¬\n",
    "                    for node_data in data.values():\n",
    "                        if len(node_data.get(\"messages\", [])) > 0:\n",
    "                            yield from output_to_responses_items_stream(node_data[\"messages\"])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error in stream handling: {e}\")\n",
    "                print(f\"   mode: {mode if 'mode' in locals() else 'unknown'}\")\n",
    "                print(f\"   data type: {type(data) if 'data' in locals() else 'unknown'}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# MLflow ëª¨ë¸ ë“±ë¡\n",
    "# ==============================================================================\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangchainSyncResponsesAgent()\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b99e9e1c-186b-46dd-b8b4-c25d09138f57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent í…ŒìŠ¤íŠ¸\n",
    "\n",
    "Agentì™€ ìƒí˜¸ì‘ìš©í•˜ì—¬ ì¶œë ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. `ResponsesAgent` ë‚´ì—ì„œ ë©”ì„œë“œë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì¶”ì í–ˆê¸° ë•Œë¬¸ì—, Agentê°€ ìˆ˜í–‰í•˜ëŠ” ê° ë‹¨ê³„ì˜ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Langchainì„ í†µí•œ LLM í˜¸ì¶œì€ autologgingì— ì˜í•´ ìë™ìœ¼ë¡œ ì¶”ì ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ì˜ ì˜ˆì‹œ ì…ë ¥ì„ ì‹¤ì œ ë„ë©”ì¸ì— ë§ëŠ” ì˜ˆì‹œë¡œ ë³€ê²½í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4db424d-892b-4259-8baf-891d49d9cd93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6555e707-d303-4f36-b284-83de80beb367",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_sync_wrapper_agent import AGENT\n",
    "\n",
    "# ë‹¨ì¼ ì‘ë‹µ í…ŒìŠ¤íŠ¸ (ë¹„ìŠ¤íŠ¸ë¦¬ë°)\n",
    "AGENT.predict(\n",
    "    {\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"}], \n",
    "        \"custom_inputs\": {\"session_id\": \"test-session-123\"}\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e282ce4e-b1cf-40fc-aac1-de45812d3f8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_sync_wrapper_agent import AGENT\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í…ŒìŠ¤íŠ¸ (ìƒì„¸ ì¶œë ¥)\n",
    "for chunk in AGENT.predict_stream(\n",
    "    {\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"ì¸ì¦ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"}], \n",
    "        \"custom_inputs\": {\"session_id\": \"test-session-123\"}\n",
    "    },\n",
    "):\n",
    "    if chunk.type != 'response.output_item.done':\n",
    "        print(\"===============\\n\")\n",
    "    print(f\"{chunk=}\\n\")\n",
    "    print(chunk.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7e0ed52-347d-42ab-ac51-6cd8a6623a73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Agentë¥¼ MLflow ëª¨ë¸ë¡œ ë¡œê¹…\n",
    "\n",
    "ë°°í¬ ì‹œ ìë™ ì¸ì¦ íŒ¨ìŠ¤ìŠ¤ë£¨ë¥¼ ìœ„í•´ Databricks ë¦¬ì†ŒìŠ¤ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **TODO**: Unity Catalog í•¨ìˆ˜ê°€ [Vector Search ì¸ë±ìŠ¤](https://docs.databricks.com/generative-ai/agent-framework/unstructured-retrieval-tools.html)ë¥¼ ì¿¼ë¦¬í•˜ê±°ë‚˜ [ì™¸ë¶€ í•¨ìˆ˜](https://docs.databricks.com/generative-ai/agent-framework/external-connection-tools.html)ë¥¼ í™œìš©í•˜ëŠ” ê²½ìš°, í•´ë‹¹ Vector Search ì¸ë±ìŠ¤ì™€ UC ì—°ê²° ê°ì²´ë¥¼ ë¦¬ì†ŒìŠ¤ë¡œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ê³µì‹ ë¬¸ì„œ](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n",
    "\n",
    "Agent ì½”ë“œë¥¼ Python íŒŒì¼ì—ì„œ ë¡œê¹…í•©ë‹ˆë‹¤. [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code) ì°¸ê³ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16716a86-a458-4485-9089-1849b4a8f286",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 12"
    }
   },
   "outputs": [],
   "source": [
    "# ë°°í¬ ì‹œ ìë™ ì¸ì¦ íŒ¨ìŠ¤ìŠ¤ë£¨ë¥¼ ìœ„í•œ Databricks ë¦¬ì†ŒìŠ¤ ì„¤ì •\n",
    "import mlflow\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint, DatabricksUCConnection\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "# TODO: í™˜ê²½ì— ë§ê²Œ ì•„ë˜ ì„¤ì •ê°’ì„ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "LLM_ENDPOINT_NAME = \"databricks-gpt-5-2\"  # ì‚¬ìš©í•  LLM ì—”ë“œí¬ì¸íŠ¸\n",
    "\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "]\n",
    "\n",
    "# ì…ë ¥ ì˜ˆì‹œ (ëª¨ë¸ ì‹œê·¸ë‹ˆì²˜ ì¶”ë¡ ìš©)\n",
    "input_example = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "        }\n",
    "    ],\n",
    "    \"custom_inputs\": {\n",
    "        \"session_id\": \"test-session-123\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# MLflowì— Agent ë¡œê¹…\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"langchain_sync_agent\",\n",
    "        python_model=\"langchain_sync_wrapper_agent.py\",\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            \"databricks-langchain\",\n",
    "            \"backoff\",\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "        ],\n",
    "        code_paths=[\n",
    "            \"langchain_sync_agent.py\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d006dd14-e9cc-4e68-aa46-69393e7af04c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## [Agent Evaluation](https://docs.databricks.com/mlflow3/genai/eval-monitor)ìœ¼ë¡œ Agent í‰ê°€\n",
    "\n",
    "í‰ê°€ ë°ì´í„°ì…‹ì˜ ìš”ì²­ì´ë‚˜ ì˜ˆìƒ ì‘ë‹µì„ ìˆ˜ì •í•˜ê³ , Agentë¥¼ ë°˜ë³µ ê°œì„ í•˜ë©´ì„œ í‰ê°€ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. MLflowë¥¼ í™œìš©í•˜ì—¬ ê³„ì‚°ëœ í’ˆì§ˆ ë©”íŠ¸ë¦­ì„ ì¶”ì í•©ë‹ˆë‹¤.\n",
    "\n",
    "[ì‚¬ì „ ì •ì˜ëœ LLM ìŠ¤ì½”ì–´ëŸ¬](https://docs.databricks.com/mlflow3/genai/eval-monitor/predefined-judge-scorers)ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, [ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­](https://docs.databricks.com/mlflow3/genai/eval-monitor/custom-scorers)ì„ ì¶”ê°€í•˜ì—¬ Agentë¥¼ í‰ê°€í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08ff3f52-99c1-49cc-9e47-dfb4707701cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 14"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Safety, RetrievalRelevance, RetrievalGroundedness\n",
    "\n",
    "# í‰ê°€ ë°ì´í„°ì…‹ ì •ì˜\n",
    "# TODO: ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ ì§ˆë¬¸ê³¼ ì˜ˆìƒ ì‘ë‹µì„ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"ì¸ì¦ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "# Agent í‰ê°€ ì‹¤í–‰\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda input: AGENT.predict({\"input\": input, \"custom_inputs\": {\"session_id\": \"evaluation-session\"}}),\n",
    "    scorers=[RelevanceToQuery(), Safety()],  # í•„ìš”ì— ë”°ë¼ ìŠ¤ì½”ì–´ëŸ¬ ì¶”ê°€\n",
    ")\n",
    "\n",
    "# MLflow UIì—ì„œ í‰ê°€ ê²°ê³¼ í™•ì¸ (ì½˜ì†” ì¶œë ¥ ì°¸ì¡°)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab5fabfc-a657-4006-8330-134b13d9e36a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ë°°í¬ ì „ Agent ê²€ì¦\n",
    "\n",
    "Agentë¥¼ ë“±ë¡í•˜ê³  ë°°í¬í•˜ê¸° ì „ì— [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) APIë¥¼ í†µí•´ ì‚¬ì „ ë°°í¬ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ê³µì‹ ë¬¸ì„œ](https://docs.databricks.com/machine-learning/model-serving/model-serving-debug.html#validate-inputs)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3acdcf0-461e-4071-bd9f-ffdf77deacac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ë°°í¬ ì „ ê²€ì¦ - ë¡œê¹…ëœ ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ”ì§€ í™•ì¸\n",
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/langchain_sync_agent\",\n",
    "    input_data={\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"}], \n",
    "        \"custom_inputs\": {\"session_id\": \"validation-session\"}\n",
    "    },\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e15b7c0-2e96-4efe-841f-1f0d4210db06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Unity Catalogì— ëª¨ë¸ ë“±ë¡\n",
    "\n",
    "ì•„ë˜ì˜ `catalog`, `schema`, `model_name`ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ MLflow ëª¨ë¸ì„ Unity Catalogì— ë“±ë¡í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4b97dfc-4218-4341-9db2-594de88caac9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: Unity Catalog ëª¨ë¸ì˜ catalog, schema, model_nameì„ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "catalog = \"ml\"\n",
    "schema = \"default\"\n",
    "model_name = \"langchain-sync-agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# Unity Catalogì— ëª¨ë¸ ë“±ë¡\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94c921e6-2f62-4add-8254-d703c5325749",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent ë°°í¬\n",
    "\n",
    "Agentë¥¼ Databricks Model Serving ì—”ë“œí¬ì¸íŠ¸ë¡œ ë°°í¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac63b207-a575-43c1-b73f-a9e0856a5597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# ì°¸ê³ : scale_to_zero=Trueë¥¼ ì „ë‹¬í•˜ë©´ ë¹„ìš© ì ˆê°ì„ ìœ„í•œ ìŠ¤ì¼€ì¼ íˆ¬ ì œë¡œê°€ í™œì„±í™”ë©ë‹ˆë‹¤.\n",
    "# í”„ë¡œë•ì…˜ ì›Œí¬ë¡œë“œì—ëŠ” ê¶Œì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ìŠ¤ì¼€ì¼ ì œë¡œ ìƒíƒœì—ì„œëŠ” ìš©ëŸ‰ì´ ë³´ì¥ë˜ì§€ ì•ŠìŒ).\n",
    "# ìŠ¤ì¼€ì¼ ì œë¡œ ìƒíƒœì˜ ì—”ë“œí¬ì¸íŠ¸ëŠ” ë‹¤ì‹œ ìŠ¤ì¼€ì¼ì—…í•˜ëŠ” ë™ì•ˆ ì‘ë‹µ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME, \n",
    "    uc_registered_model_info.version, \n",
    "    tags={\"endpointSource\": \"local_development\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1171890-c406-4b52-9253-e19f7357cab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "Agentê°€ ë°°í¬ë˜ë©´ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "- **AI Playgroundì—ì„œ í…ŒìŠ¤íŠ¸**: ì¶”ê°€ ê²€ì¦ì„ ìœ„í•´ ëŒ€í™”í˜•ìœ¼ë¡œ Agent í…ŒìŠ¤íŠ¸\n",
    "- **í”¼ë“œë°± ìˆ˜ì§‘**: ì¡°ì§ ë‚´ ì „ë¬¸ê°€(SME)ì™€ Agent ê³µìœ í•˜ì—¬ í”¼ë“œë°± ìˆ˜ì§‘\n",
    "- **í”„ë¡œë•ì…˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì— í†µí•©**: ì‹¤ì œ ì„œë¹„ìŠ¤ì— Agent ì„ë² ë”©\n",
    "\n",
    "ìì„¸í•œ ë‚´ìš©ì€ [ê³µì‹ ë¬¸ì„œ](https://docs.databricks.com/generative-ai/deploy-agent.html)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7131cf6-6ad8-4035-a335-9c09086f1f2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "llms_txt_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
